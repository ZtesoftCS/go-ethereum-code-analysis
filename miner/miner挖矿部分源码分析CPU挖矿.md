## agent
agent æ˜¯å…·ä½“æ‰§è¡ŒæŒ–çŸ¿çš„å¯¹è±¡ã€‚ å®ƒæ‰§è¡Œçš„æµç¨‹å°±æ˜¯ï¼Œæ¥å—è®¡ç®—å¥½äº†çš„åŒºå—å¤´ï¼Œ è®¡ç®—mixhashå’Œnonceï¼Œ æŠŠæŒ–çŸ¿å¥½çš„åŒºå—å¤´è¿”å›ã€‚

æ„é€ CpuAgent, ä¸€èˆ¬æƒ…å†µä¸‹ä¸ä¼šä½¿ç”¨CPUæ¥è¿›è¡ŒæŒ–çŸ¿ï¼Œä¸€èˆ¬æ¥è¯´æŒ–çŸ¿éƒ½æ˜¯ä½¿ç”¨çš„ä¸“é—¨çš„GPUè¿›è¡ŒæŒ–çŸ¿ï¼Œ GPUæŒ–çŸ¿çš„ä»£ç ä¸ä¼šåœ¨è¿™é‡Œä½“ç°ã€‚

	type CpuAgent struct {
		mu sync.Mutex
	
		workCh        chan *Work       // æ¥å—æŒ–çŸ¿ä»»åŠ¡çš„é€šé“
		stop          chan struct{}
		quitCurrentOp chan struct{}
		returnCh      chan<- *Result   // æŒ–çŸ¿å®Œæˆåçš„è¿”å›channel
	
		chain  consensus.ChainReader // è·å–åŒºå—é“¾çš„ä¿¡æ¯
		engine consensus.Engine      // ä¸€è‡´æ€§å¼•æ“ï¼Œè¿™é‡ŒæŒ‡çš„æ˜¯Powå¼•æ“
	
		isMining int32 // isMining indicates whether the agent is currently mining
	}
	
	func NewCpuAgent(chain consensus.ChainReader, engine consensus.Engine) *CpuAgent {
		miner := &CpuAgent{
			chain:  chain,
			engine: engine,
			stop:   make(chan struct{}, 1),
			workCh: make(chan *Work, 1),
		}
		return miner
	}

è®¾ç½®è¿”å›å€¼channelå’Œå¾—åˆ°Workçš„channelï¼Œ æ–¹ä¾¿å¤–ç•Œä¼ å€¼å’Œå¾—åˆ°è¿”å›ä¿¡æ¯ã€‚

	func (self *CpuAgent) Work() chan<- *Work            { return self.workCh }
	func (self *CpuAgent) SetReturnCh(ch chan<- *Result) { self.returnCh = ch }

å¯åŠ¨å’Œæ¶ˆæ¯å¾ªç¯ï¼Œå¦‚æœå·²ç»å¯åŠ¨æŒ–çŸ¿ï¼Œé‚£ä¹ˆç›´æ¥é€€å‡ºï¼Œ å¦åˆ™å¯åŠ¨update è¿™ä¸ªgoroutine
update ä»workChæ¥å—ä»»åŠ¡ï¼Œè¿›è¡ŒæŒ–çŸ¿ï¼Œæˆ–è€…æ˜¯æ¥å—é€€å‡ºä¿¡æ¯ï¼Œé€€å‡ºã€‚
	
	func (self *CpuAgent) Start() {
		if !atomic.CompareAndSwapInt32(&self.isMining, 0, 1) {
			return // agent already started
		}
		go self.update()
	}
	
	func (self *CpuAgent) update() {
	out:
		for {
			select {
			case work := <-self.workCh:
				self.mu.Lock()
				if self.quitCurrentOp != nil {
					close(self.quitCurrentOp)
				}
				self.quitCurrentOp = make(chan struct{})
				go self.mine(work, self.quitCurrentOp)
				self.mu.Unlock()
			case <-self.stop:
				self.mu.Lock()
				if self.quitCurrentOp != nil {
					close(self.quitCurrentOp)
					self.quitCurrentOp = nil
				}
				self.mu.Unlock()
				break out
			}
		}
	}

mine, æŒ–çŸ¿ï¼Œè°ƒç”¨ä¸€è‡´æ€§å¼•æ“è¿›è¡ŒæŒ–çŸ¿ï¼Œ å¦‚æœæŒ–çŸ¿æˆåŠŸï¼ŒæŠŠæ¶ˆæ¯å‘é€åˆ°returnChä¸Šé¢ã€‚
	
	func (self *CpuAgent) mine(work *Work, stop <-chan struct{}) {
		if result, err := self.engine.Seal(self.chain, work.Block, stop); result != nil {
			log.Info("Successfully sealed new block", "number", result.Number(), "hash", result.Hash())
			self.returnCh <- &Result{work, result}
		} else {
			if err != nil {
				log.Warn("Block sealing failed", "err", err)
			}
			self.returnCh <- nil
		}
	}
GetHashRateï¼Œ è¿™ä¸ªå‡½æ•°è¿”å›å½“å‰çš„HashRateã€‚

	func (self *CpuAgent) GetHashRate() int64 {
		if pow, ok := self.engine.(consensus.PoW); ok {
			return int64(pow.Hashrate())
		}
		return 0
	}


## remote_agent
remote_agent æä¾›äº†ä¸€å¥—RPCæ¥å£ï¼Œå¯ä»¥å®ç°è¿œç¨‹çŸ¿å·¥è¿›è¡Œé‡‡çŸ¿çš„åŠŸèƒ½ã€‚ æ¯”å¦‚æˆ‘æœ‰ä¸€ä¸ªçŸ¿æœºï¼ŒçŸ¿æœºå†…éƒ¨æ²¡æœ‰è¿è¡Œä»¥å¤ªåŠèŠ‚ç‚¹ï¼ŒçŸ¿æœºé¦–å…ˆä»remote_agentè·å–å½“å‰çš„ä»»åŠ¡ï¼Œç„¶åè¿›è¡ŒæŒ–çŸ¿è®¡ç®—ï¼Œå½“æŒ–çŸ¿å®Œæˆåï¼Œæäº¤è®¡ç®—ç»“æœï¼Œå®ŒæˆæŒ–çŸ¿ã€‚ 

æ•°æ®ç»“æ„å’Œæ„é€ 

	type RemoteAgent struct {
		mu sync.Mutex
	
		quitCh   chan struct{}
		workCh   chan *Work  		// æ¥å—ä»»åŠ¡
		returnCh chan<- *Result		// ç»“æœè¿”å›
	
		chain       consensus.ChainReader
		engine      consensus.Engine
		currentWork *Work	//å½“å‰çš„ä»»åŠ¡
		work        map[common.Hash]*Work // å½“å‰è¿˜æ²¡æœ‰æäº¤çš„ä»»åŠ¡ï¼Œæ­£åœ¨è®¡ç®—
	
		hashrateMu sync.RWMutex
		hashrate   map[common.Hash]hashrate  // æ­£åœ¨è®¡ç®—çš„ä»»åŠ¡çš„hashrate
	
		running int32 // running indicates whether the agent is active. Call atomically
	}
	
	func NewRemoteAgent(chain consensus.ChainReader, engine consensus.Engine) *RemoteAgent {
		return &RemoteAgent{
			chain:    chain,
			engine:   engine,
			work:     make(map[common.Hash]*Work),
			hashrate: make(map[common.Hash]hashrate),
		}
	}

å¯åŠ¨å’Œåœæ­¢
	
	func (a *RemoteAgent) Start() {
		if !atomic.CompareAndSwapInt32(&a.running, 0, 1) {
			return
		}
		a.quitCh = make(chan struct{})
		a.workCh = make(chan *Work, 1)
		go a.loop(a.workCh, a.quitCh)
	}
	
	func (a *RemoteAgent) Stop() {
		if !atomic.CompareAndSwapInt32(&a.running, 1, 0) {
			return
		}
		close(a.quitCh)
		close(a.workCh)
	}
å¾—åˆ°è¾“å…¥è¾“å‡ºçš„channelï¼Œè¿™ä¸ªå’Œagent.goä¸€æ ·ã€‚

	func (a *RemoteAgent) Work() chan<- *Work {
		return a.workCh
	}
	
	func (a *RemoteAgent) SetReturnCh(returnCh chan<- *Result) {
		a.returnCh = returnCh
	}

loopæ–¹æ³•,å’Œagent.goé‡Œé¢åšçš„å·¥ä½œæ¯”è¾ƒç±»ä¼¼ï¼Œ å½“æ¥æ”¶åˆ°ä»»åŠ¡çš„æ—¶å€™ï¼Œå°±å­˜æ”¾åœ¨currentWorkå­—æ®µé‡Œé¢ã€‚ å¦‚æœ84ç§’è¿˜æ²¡æœ‰å®Œæˆä¸€ä¸ªå·¥ä½œï¼Œé‚£ä¹ˆå°±åˆ é™¤è¿™ä¸ªå·¥ä½œï¼Œ å¦‚æœ10ç§’æ²¡æœ‰æ”¶åˆ°hashrateçš„æŠ¥å‘Šï¼Œé‚£ä¹ˆåˆ é™¤è¿™ä¸ªè¿½è¸ª/ã€‚
	
	// loop monitors mining events on the work and quit channels, updating the internal
	// state of the rmeote miner until a termination is requested.
	//
	// Note, the reason the work and quit channels are passed as parameters is because
	// RemoteAgent.Start() constantly recreates these channels, so the loop code cannot
	// assume data stability in these member fields.
	func (a *RemoteAgent) loop(workCh chan *Work, quitCh chan struct{}) {
		ticker := time.NewTicker(5 * time.Second)
		defer ticker.Stop()
	
		for {
			select {
			case <-quitCh:
				return
			case work := <-workCh:
				a.mu.Lock()
				a.currentWork = work
				a.mu.Unlock()
			case <-ticker.C:
				// cleanup
				a.mu.Lock()
				for hash, work := range a.work {
					if time.Since(work.createdAt) > 7*(12*time.Second) {
						delete(a.work, hash)
					}
				}
				a.mu.Unlock()
	
				a.hashrateMu.Lock()
				for id, hashrate := range a.hashrate {
					if time.Since(hashrate.ping) > 10*time.Second {
						delete(a.hashrate, id)
					}
				}
				a.hashrateMu.Unlock()
			}
		}
	}

GetWorkï¼Œè¿™ä¸ªæ–¹æ³•ç”±è¿œç¨‹çŸ¿å·¥è°ƒç”¨ï¼Œè·å–å½“å‰çš„æŒ–çŸ¿ä»»åŠ¡ã€‚
	
	func (a *RemoteAgent) GetWork() ([3]string, error) {
		a.mu.Lock()
		defer a.mu.Unlock()
	
		var res [3]string
	
		if a.currentWork != nil {
			block := a.currentWork.Block
	
			res[0] = block.HashNoNonce().Hex()
			seedHash := ethash.SeedHash(block.NumberU64())
			res[1] = common.BytesToHash(seedHash).Hex()
			// Calculate the "target" to be returned to the external miner
			n := big.NewInt(1)
			n.Lsh(n, 255)
			n.Div(n, block.Difficulty())
			n.Lsh(n, 1)
			res[2] = common.BytesToHash(n.Bytes()).Hex()
	
			a.work[block.HashNoNonce()] = a.currentWork
			return res, nil
		}
		return res, errors.New("No work available yet, don't panic.")
	}

SubmitWork, è¿œç¨‹çŸ¿å·¥ä¼šè°ƒç”¨è¿™ä¸ªæ–¹æ³•æäº¤æŒ–çŸ¿çš„ç»“æœã€‚ å¯¹ç»“æœè¿›è¡ŒéªŒè¯ä¹‹åæäº¤åˆ°returnCh

	// SubmitWork tries to inject a pow solution into the remote agent, returning
	// whether the solution was accepted or not (not can be both a bad pow as well as
	// any other error, like no work pending).
	func (a *RemoteAgent) SubmitWork(nonce types.BlockNonce, mixDigest, hash common.Hash) bool {
		a.mu.Lock()
		defer a.mu.Unlock()
	
		// Make sure the work submitted is present
		work := a.work[hash]
		if work == nil {
			log.Info("Work submitted but none pending", "hash", hash)
			return false
		}
		// Make sure the Engine solutions is indeed valid
		result := work.Block.Header()
		result.Nonce = nonce
		result.MixDigest = mixDigest
	
		if err := a.engine.VerifySeal(a.chain, result); err != nil {
			log.Warn("Invalid proof-of-work submitted", "hash", hash, "err", err)
			return false
		}
		block := work.Block.WithSeal(result)
	
		// Solutions seems to be valid, return to the miner and notify acceptance
		a.returnCh <- &Result{work, block}
		delete(a.work, hash)
	
		return true
	}

SubmitHashrate, æäº¤hashç®—åŠ›

	func (a *RemoteAgent) SubmitHashrate(id common.Hash, rate uint64) {
		a.hashrateMu.Lock()
		defer a.hashrateMu.Unlock()
	
		a.hashrate[id] = hashrate{time.Now(), rate}
	}


## unconfirmed

unconfirmedæ˜¯ä¸€ä¸ªæ•°æ®ç»“æ„ï¼Œç”¨æ¥è·Ÿè¸ªç”¨æˆ·æœ¬åœ°çš„æŒ–çŸ¿ä¿¡æ¯çš„ï¼Œæ¯”å¦‚æŒ–å‡ºäº†ä¸€ä¸ªå—ï¼Œé‚£ä¹ˆç­‰å¾…è¶³å¤Ÿçš„åç»­åŒºå—ç¡®è®¤ä¹‹å(5ä¸ª)ï¼Œå†æŸ¥çœ‹æœ¬åœ°æŒ–çŸ¿çš„åŒºå—æ˜¯å¦åŒ…å«åœ¨è§„èŒƒçš„åŒºå—é“¾å†…éƒ¨ã€‚

æ•°æ®ç»“æ„
	
	// headerRetriever is used by the unconfirmed block set to verify whether a previously
	// mined block is part of the canonical chain or not.
	// headerRetrieverç”±æœªç¡®è®¤çš„å—ç»„ä½¿ç”¨ï¼Œä»¥éªŒè¯å…ˆå‰æŒ–æ˜çš„å—æ˜¯å¦æ˜¯è§„èŒƒé“¾çš„ä¸€éƒ¨åˆ†ã€‚
	type headerRetriever interface {
		// GetHeaderByNumber retrieves the canonical header associated with a block number.
		GetHeaderByNumber(number uint64) *types.Header
	}
	
	// unconfirmedBlock is a small collection of metadata about a locally mined block
	// that is placed into a unconfirmed set for canonical chain inclusion tracking.
	// unconfirmedBlock æ˜¯æœ¬åœ°æŒ–æ˜åŒºå—çš„ä¸€ä¸ªå°çš„å…ƒæ•°æ®çš„é›†åˆï¼Œç”¨æ¥æ”¾å…¥æœªç¡®è®¤çš„é›†åˆç”¨æ¥è¿½è¸ªæœ¬åœ°æŒ–æ˜çš„åŒºå—æ˜¯å¦è¢«åŒ…å«è¿›å…¥è§„èŒƒçš„åŒºå—é“¾
	type unconfirmedBlock struct {
		index uint64
		hash  common.Hash
	}
	
	// unconfirmedBlocks implements a data structure to maintain locally mined blocks
	// have have not yet reached enough maturity to guarantee chain inclusion. It is
	// used by the miner to provide logs to the user when a previously mined block
	// has a high enough guarantee to not be reorged out of te canonical chain.	
	// unconfirmedBlocks å®ç°äº†ä¸€ä¸ªæ•°æ®ç»“æ„ï¼Œç”¨æ¥ç®¡ç†æœ¬åœ°æŒ–æ˜çš„åŒºå—ï¼Œè¿™äº›åŒºå—è¿˜æ²¡æœ‰è¾¾åˆ°è¶³å¤Ÿçš„ä¿¡ä»»åº¦æ¥è¯æ˜ä»–ä»¬å·²ç»è¢«è§„èŒƒçš„åŒºå—é“¾æ¥å—ã€‚ å®ƒç”¨æ¥ç»™çŸ¿å·¥æä¾›ä¿¡æ¯ï¼Œä»¥ä¾¿ä»–ä»¬äº†è§£ä»–ä»¬ä¹‹å‰æŒ–åˆ°çš„åŒºå—æ˜¯å¦è¢«åŒ…å«è¿›å…¥äº†è§„èŒƒçš„åŒºå—é“¾ã€‚
	type unconfirmedBlocks struct {
		chain  headerRetriever // Blockchain to verify canonical status through éœ€è¦éªŒè¯çš„åŒºå—é“¾ ç”¨è¿™ä¸ªæ¥å£æ¥è·å–å½“å‰çš„è§„èŒƒçš„åŒºå—å¤´ä¿¡æ¯
		depth  uint            // Depth after which to discard previous blocks ç»è¿‡å¤šå°‘ä¸ªåŒºå—ä¹‹åä¸¢å¼ƒä¹‹å‰çš„åŒºå—
		blocks *ring.Ring      // Block infos to allow canonical chain cross checks // åŒºå—ä¿¡æ¯ï¼Œä»¥å…è®¸è§„èŒƒé“¾äº¤å‰æ£€æŸ¥
		lock   sync.RWMutex    // Protects the fields from concurrent access
	}

	// newUnconfirmedBlocks returns new data structure to track currently unconfirmed blocks.
	func newUnconfirmedBlocks(chain headerRetriever, depth uint) *unconfirmedBlocks {
		return &unconfirmedBlocks{
			chain: chain,
			depth: depth,
		}
	}

æ’å…¥è·Ÿè¸ªåŒºå—, å½“çŸ¿å·¥æŒ–åˆ°ä¸€ä¸ªåŒºå—çš„æ—¶å€™è°ƒç”¨ï¼Œ indexæ˜¯åŒºå—çš„é«˜åº¦ï¼Œ hashæ˜¯åŒºå—çš„hashå€¼ã€‚
	
	
	// Insert adds a new block to the set of unconfirmed ones.
	func (set *unconfirmedBlocks) Insert(index uint64, hash common.Hash) {
		// If a new block was mined locally, shift out any old enough blocks
		// å¦‚æœä¸€ä¸ªæœ¬åœ°çš„åŒºå—æŒ–åˆ°äº†ï¼Œé‚£ä¹ˆç§»å‡ºå·²ç»è¶…è¿‡depthçš„åŒºå—
		set.Shift(index)
	
		// Create the new item as its own ring
		// å¾ªç¯é˜Ÿåˆ—çš„æ“ä½œã€‚
		item := ring.New(1)
		item.Value = &unconfirmedBlock{
			index: index,
			hash:  hash,
		}
		// Set as the initial ring or append to the end
		set.lock.Lock()
		defer set.lock.Unlock()
	
		if set.blocks == nil {
			set.blocks = item
		} else {
			// ç§»åŠ¨åˆ°å¾ªç¯é˜Ÿåˆ—çš„æœ€åä¸€ä¸ªå…ƒç´ æ’å…¥item
			set.blocks.Move(-1).Link(item)
		}
		// Display a log for the user to notify of a new mined block unconfirmed
		log.Info("ğŸ”¨ mined potential block", "number", index, "hash", hash)
	}
Shiftæ–¹æ³•ä¼šåˆ é™¤é‚£äº›indexè¶…è¿‡ä¼ å…¥çš„index-depthçš„åŒºå—ï¼Œå¹¶æ£€æŸ¥ä»–ä»¬æ˜¯å¦åœ¨è§„èŒƒçš„åŒºå—é“¾ä¸­ã€‚
	
	// Shift drops all unconfirmed blocks from the set which exceed the unconfirmed sets depth
	// allowance, checking them against the canonical chain for inclusion or staleness
	// report.
	func (set *unconfirmedBlocks) Shift(height uint64) {
		set.lock.Lock()
		defer set.lock.Unlock()
	
		for set.blocks != nil {
			// Retrieve the next unconfirmed block and abort if too fresh
			// å› ä¸ºblocksä¸­çš„åŒºå—éƒ½æ˜¯æŒ‰é¡ºåºæ’åˆ—çš„ã€‚æ’åœ¨æœ€å¼€å§‹çš„è‚¯å®šæ˜¯æœ€è€çš„åŒºå—ã€‚
			// æ‰€ä»¥æ¯æ¬¡åªéœ€è¦æ£€æŸ¥æœ€å¼€å§‹çš„é‚£ä¸ªåŒºå—ï¼Œå¦‚æœå¤„ç†å®Œäº†ï¼Œå°±ä»å¾ªç¯é˜Ÿåˆ—é‡Œé¢æ‘˜é™¤ã€‚
			next := set.blocks.Value.(*unconfirmedBlock)
			if next.index+uint64(set.depth) > height { // å¦‚æœè¶³å¤Ÿè€äº†ã€‚
				break
			}
			// Block seems to exceed depth allowance, check for canonical status
			// æŸ¥è¯¢ é‚£ä¸ªåŒºå—é«˜åº¦çš„åŒºå—å¤´
			header := set.chain.GetHeaderByNumber(next.index)
			switch {
			case header == nil:
				log.Warn("Failed to retrieve header of mined block", "number", next.index, "hash", next.hash)
			case header.Hash() == next.hash: // å¦‚æœåŒºå—å¤´å°±ç­‰äºæˆ‘ä»¬è‡ªå·±ï¼Œ
				log.Info("ğŸ”— block reached canonical chain", "number", next.index, "hash", next.hash)
			default: // å¦åˆ™è¯´æ˜æˆ‘ä»¬åœ¨ä¾§é“¾ä¸Šé¢ã€‚
				log.Info("â‘‚ block  became a side fork", "number", next.index, "hash", next.hash)
			}
			// Drop the block out of the ring
			// ä»å¾ªç¯é˜Ÿåˆ—åˆ é™¤
			if set.blocks.Value == set.blocks.Next().Value {
				// å¦‚æœå½“å‰çš„å€¼å°±ç­‰äºæˆ‘ä»¬è‡ªå·±ï¼Œè¯´æ˜åªæœ‰å¾ªç¯é˜Ÿåˆ—åªæœ‰ä¸€ä¸ªå…ƒç´ ï¼Œé‚£ä¹ˆè®¾ç½®æœªnil
				set.blocks = nil
			} else {
				// å¦åˆ™ç§»åŠ¨åˆ°æœ€åï¼Œç„¶ååˆ é™¤ä¸€ä¸ªï¼Œå†ç§»åŠ¨åˆ°æœ€å‰ã€‚
				set.blocks = set.blocks.Move(-1)
				set.blocks.Unlink(1)
				set.blocks = set.blocks.Move(1)
			}
		}
	}

## worker.go
worker å†…éƒ¨åŒ…å«äº†å¾ˆå¤šagentï¼Œå¯ä»¥åŒ…å«ä¹‹å‰æåˆ°çš„agentå’Œremote_agentã€‚ workeråŒæ—¶è´Ÿè´£æ„å»ºåŒºå—å’Œå¯¹è±¡ã€‚åŒæ—¶æŠŠä»»åŠ¡æä¾›ç»™agentã€‚

æ•°æ®ç»“æ„ï¼š

Agentæ¥å£
	
	// Agent can register themself with the worker
	type Agent interface {
		Work() chan<- *Work
		SetReturnCh(chan<- *Result)
		Stop()
		Start()
		GetHashRate() int64
	}

Workç»“æ„ï¼ŒWorkå­˜å‚¨äº†å·¥ä½œè€…çš„å½“æ—¶çš„ç¯å¢ƒï¼Œå¹¶ä¸”æŒæœ‰æ‰€æœ‰çš„æš‚æ—¶çš„çŠ¶æ€ä¿¡æ¯ã€‚

	// Work is the workers current environment and holds
	// all of the current state information
	type Work struct {
		config *params.ChainConfig
		signer types.Signer			// ç­¾åè€…
	
		state     *state.StateDB // apply state changes here çŠ¶æ€æ•°æ®åº“
		ancestors *set.Set       // ancestor set (used for checking uncle parent validity)  ç¥–å…ˆé›†åˆï¼Œç”¨æ¥æ£€æŸ¥ç¥–å…ˆæ˜¯å¦æœ‰æ•ˆ
		family    *set.Set       // family set (used for checking uncle invalidity) å®¶æ—é›†åˆï¼Œç”¨æ¥æ£€æŸ¥ç¥–å…ˆçš„æ— æ•ˆæ€§
		uncles    *set.Set       // uncle set  unclesé›†åˆ
		tcount    int            // tx count in cycle è¿™ä¸ªå‘¨æœŸçš„äº¤æ˜“æ•°é‡
	
		Block *types.Block // the new block  //æ–°çš„åŒºå—
	
		header   *types.Header			// åŒºå—å¤´
		txs      []*types.Transaction   // äº¤æ˜“
		receipts []*types.Receipt  		// æ”¶æ®
	
		createdAt time.Time 			// åˆ›å»ºæ—¶é—´
	}
	
	type Result struct {  //ç»“æœ
		Work  *Work
		Block *types.Block
	}
worker
	
	// worker is the main object which takes care of applying messages to the new state
	// å·¥ä½œè€…æ˜¯è´Ÿè´£å°†æ¶ˆæ¯åº”ç”¨åˆ°æ–°çŠ¶æ€çš„ä¸»è¦å¯¹è±¡
	type worker struct {
		config *params.ChainConfig
		engine consensus.Engine
		mu sync.Mutex
		// update loop
		mux          *event.TypeMux
		txCh         chan core.TxPreEvent		// ç”¨æ¥æ¥å—txPoolé‡Œé¢çš„äº¤æ˜“çš„é€šé“
		txSub        event.Subscription			// ç”¨æ¥æ¥å—txPoolé‡Œé¢çš„äº¤æ˜“çš„è®¢é˜…å™¨
		chainHeadCh  chan core.ChainHeadEvent	// ç”¨æ¥æ¥å—åŒºå—å¤´çš„é€šé“
		chainHeadSub event.Subscription
		chainSideCh  chan core.ChainSideEvent	// ç”¨æ¥æ¥å—ä¸€ä¸ªåŒºå—é“¾ä»è§„èŒƒåŒºå—é“¾ç§»å‡ºçš„é€šé“
		chainSideSub event.Subscription
		wg           sync.WaitGroup
	
		agents map[Agent]struct{}				// æ‰€æœ‰çš„agent
		recv   chan *Result						// agentä¼šæŠŠç»“æœå‘é€åˆ°è¿™ä¸ªé€šé“
	
		eth     Backend							// ethçš„åè®®
		chain   *core.BlockChain				// åŒºå—é“¾
		proc    core.Validator					// åŒºå—é“¾éªŒè¯å™¨
		chainDb ethdb.Database					// åŒºå—é“¾æ•°æ®åº“
	
		coinbase common.Address					// æŒ–çŸ¿è€…çš„åœ°å€
		extra    []byte							// 
		
		snapshotMu    sync.RWMutex				// å¿«ç…§ RWMutexï¼ˆå¿«ç…§è¯»å†™é”ï¼‰
		snapshotBlock *types.Block				// å¿«ç…§ Block
		snapshotState *state.StateDB				// å¿«ç…§ StateDB
		
		currentMu sync.Mutex
		current   *Work
	
		uncleMu        sync.Mutex
		possibleUncles map[common.Hash]*types.Block	//å¯èƒ½çš„å”çˆ¶èŠ‚ç‚¹
	
		unconfirmed *unconfirmedBlocks // set of locally mined blocks pending canonicalness confirmations
	
		// atomic status counters
		mining int32
		atWork int32
	}

æ„é€ 
	
	func newWorker(config *params.ChainConfig, engine consensus.Engine, coinbase common.Address, eth Backend, mux *event.TypeMux) *worker {
		worker := &worker{
			config:         config,
			engine:         engine,
			eth:            eth,
			mux:            mux,
			txCh:           make(chan core.TxPreEvent, txChanSize), // 4096
			chainHeadCh:    make(chan core.ChainHeadEvent, chainHeadChanSize), // 10
			chainSideCh:    make(chan core.ChainSideEvent, chainSideChanSize), // 10
			chainDb:        eth.ChainDb(),
			recv:           make(chan *Result, resultQueueSize), // 10
			chain:          eth.BlockChain(),
			proc:           eth.BlockChain().Validator(),
			possibleUncles: make(map[common.Hash]*types.Block),
			coinbase:       coinbase,
			agents:         make(map[Agent]struct{}),
			unconfirmed:    newUnconfirmedBlocks(eth.BlockChain(), miningLogAtDepth),
		}
		// Subscribe TxPreEvent for tx pool
		worker.txSub = eth.TxPool().SubscribeTxPreEvent(worker.txCh)
		// Subscribe events for blockchain
		worker.chainHeadSub = eth.BlockChain().SubscribeChainHeadEvent(worker.chainHeadCh)
		worker.chainSideSub = eth.BlockChain().SubscribeChainSideEvent(worker.chainSideCh)
		go worker.update()
	
		go worker.wait()
		worker.commitNewWork()
	
		return worker
	}

update
	
	func (self *worker) update() {
		defer self.txSub.Unsubscribe()
		defer self.chainHeadSub.Unsubscribe()
		defer self.chainSideSub.Unsubscribe()
	
		for {
			// A real event arrived, process interesting content
			select {
			// Handle ChainHeadEvent å½“æ¥æ”¶åˆ°ä¸€ä¸ªåŒºå—å¤´çš„ä¿¡æ¯çš„æ—¶å€™ï¼Œé©¬ä¸Šå¼€å¯æŒ–çŸ¿æœåŠ¡ã€‚
			case <-self.chainHeadCh:
				self.commitNewWork()
	
			// Handle ChainSideEvent æ¥æ”¶ä¸åœ¨è§„èŒƒçš„åŒºå—é“¾çš„åŒºå—ï¼ŒåŠ å…¥åˆ°æ½œåœ¨çš„å”çˆ¶é›†åˆ
			case ev := <-self.chainSideCh:
				self.uncleMu.Lock()
				self.possibleUncles[ev.Block.Hash()] = ev.Block
				self.uncleMu.Unlock()
	
			// Handle TxPreEvent æ¥æ”¶åˆ°txPoolé‡Œé¢çš„äº¤æ˜“ä¿¡æ¯çš„æ—¶å€™ã€‚
			case ev := <-self.txCh:
				// Apply transaction to the pending state if we're not mining
				// å¦‚æœå½“å‰æ²¡æœ‰æŒ–çŸ¿ï¼Œ é‚£ä¹ˆæŠŠäº¤æ˜“åº”ç”¨åˆ°å½“å‰çš„çŠ¶æ€ä¸Šï¼Œä»¥ä¾¿é©¬ä¸Šå¼€å¯æŒ–çŸ¿ä»»åŠ¡ã€‚
				if atomic.LoadInt32(&self.mining) == 0 {
					self.currentMu.Lock()
					acc, _ := types.Sender(self.current.signer, ev.Tx)
					txs := map[common.Address]types.Transactions{acc: {ev.Tx}}
					txset := types.NewTransactionsByPriceAndNonce(self.current.signer, txs)
	
					self.current.commitTransactions(self.mux, txset, self.chain, self.coinbase)
					self.currentMu.Unlock()
				}
	
			// System stopped
			case <-self.txSub.Err():
				return
			case <-self.chainHeadSub.Err():
				return
			case <-self.chainSideSub.Err():
				return
			}
		}
	}


commitNewWork æäº¤æ–°çš„ä»»åŠ¡

	
	func (self *worker) commitNewWork() {
		self.mu.Lock()
		defer self.mu.Unlock()
		self.uncleMu.Lock()
		defer self.uncleMu.Unlock()
		self.currentMu.Lock()
		defer self.currentMu.Unlock()
	
		tstart := time.Now()
		parent := self.chain.CurrentBlock()
	
		tstamp := tstart.Unix()
		if parent.Time().Cmp(new(big.Int).SetInt64(tstamp)) >= 0 { // ä¸èƒ½å‡ºç°æ¯”parentçš„æ—¶é—´è¿˜å°‘çš„æƒ…å†µ
			tstamp = parent.Time().Int64() + 1
		}
		// this will ensure we're not going off too far in the future
		// æˆ‘ä»¬çš„æ—¶é—´ä¸è¦è¶…è¿‡ç°åœ¨çš„æ—¶é—´å¤ªè¿œï¼Œ é‚£ä¹ˆç­‰å¾…ä¸€æ®µæ—¶é—´ï¼Œ 
		// æ„Ÿè§‰è¿™ä¸ªåŠŸèƒ½å®Œå…¨æ˜¯ä¸ºäº†æµ‹è¯•å®ç°çš„ï¼Œ å¦‚æœæ˜¯çœŸå®çš„æŒ–çŸ¿ç¨‹åºï¼Œåº”è¯¥ä¸ä¼šç­‰å¾…ã€‚
		if now := time.Now().Unix(); tstamp > now+1 {
			wait := time.Duration(tstamp-now) * time.Second
			log.Info("Mining too far in the future", "wait", common.PrettyDuration(wait))
			time.Sleep(wait)
		}
	
		num := parent.Number()
		header := &types.Header{
			ParentHash: parent.Hash(),
			Number:     num.Add(num, common.Big1),
			GasLimit:   core.CalcGasLimit(parent),
			GasUsed:    new(big.Int),
			Extra:      self.extra,
			Time:       big.NewInt(tstamp),
		}
		// Only set the coinbase if we are mining (avoid spurious block rewards)
		// åªæœ‰å½“æˆ‘ä»¬æŒ–çŸ¿çš„æ—¶å€™æ‰è®¾ç½®coinbase(é¿å…è™šå‡çš„å—å¥–åŠ±ï¼Ÿ TODO æ²¡æ‡‚)
		if atomic.LoadInt32(&self.mining) == 1 {
			header.Coinbase = self.coinbase
		}
		if err := self.engine.Prepare(self.chain, header); err != nil {
			log.Error("Failed to prepare header for mining", "err", err)
			return
		}
		// If we are care about TheDAO hard-fork check whether to override the extra-data or not
		// æ ¹æ®æˆ‘ä»¬æ˜¯å¦å…³å¿ƒDAOç¡¬åˆ†å‰æ¥å†³å®šæ˜¯å¦è¦†ç›–é¢å¤–çš„æ•°æ®ã€‚
		if daoBlock := self.config.DAOForkBlock; daoBlock != nil {
			// Check whether the block is among the fork extra-override range
			// æ£€æŸ¥åŒºå—æ˜¯å¦åœ¨ DAOç¡¬åˆ†å‰çš„èŒƒå›´å†…   [daoblock,daoblock+limit]
			limit := new(big.Int).Add(daoBlock, params.DAOForkExtraRange)
			if header.Number.Cmp(daoBlock) >= 0 && header.Number.Cmp(limit) < 0 {
				// Depending whether we support or oppose the fork, override differently
				if self.config.DAOForkSupport { // å¦‚æœæˆ‘ä»¬æ”¯æŒDAO é‚£ä¹ˆè®¾ç½®ä¿ç•™çš„é¢å¤–çš„æ•°æ®
					header.Extra = common.CopyBytes(params.DAOForkBlockExtra)
				} else if bytes.Equal(header.Extra, params.DAOForkBlockExtra) {
					header.Extra = []byte{} // If miner opposes, don't let it use the reserved extra-data // å¦åˆ™ä¸ä½¿ç”¨ä¿ç•™çš„é¢å¤–æ•°æ®
				}
			}
		}
		// Could potentially happen if starting to mine in an odd state.
		err := self.makeCurrent(parent, header) // ç”¨æ–°çš„åŒºå—å¤´æ¥è®¾ç½®å½“å‰çš„çŠ¶æ€
		if err != nil {
			log.Error("Failed to create mining context", "err", err)
			return
		}
		// Create the current work task and check any fork transitions needed
		work := self.current
		if self.config.DAOForkSupport && self.config.DAOForkBlock != nil && self.config.DAOForkBlock.Cmp(header.Number) == 0 {
			misc.ApplyDAOHardFork(work.state)  // æŠŠDAOé‡Œé¢çš„èµ„é‡‘è½¬ç§»åˆ°æŒ‡å®šçš„è´¦æˆ·ã€‚
		}
		pending, err := self.eth.TxPool().Pending() //å¾—åˆ°é˜»å¡çš„èµ„é‡‘
		if err != nil {
			log.Error("Failed to fetch pending transactions", "err", err)
			return
		}
		// åˆ›å»ºäº¤æ˜“ã€‚ è¿™ä¸ªæ–¹æ³•åç»­ä»‹ç»
		txs := types.NewTransactionsByPriceAndNonce(self.current.signer, pending)
		// æäº¤äº¤æ˜“ è¿™ä¸ªæ–¹æ³•åç»­ä»‹ç»	
		work.commitTransactions(self.mux, txs, self.chain, self.coinbase)
	
		// compute uncles for the new block.
		var (
			uncles    []*types.Header
			badUncles []common.Hash
		)
		for hash, uncle := range self.possibleUncles {
			if len(uncles) == 2 {
				break
			}
			if err := self.commitUncle(work, uncle.Header()); err != nil {
				log.Trace("Bad uncle found and will be removed", "hash", hash)
				log.Trace(fmt.Sprint(uncle))
	
				badUncles = append(badUncles, hash)
			} else {
				log.Debug("Committing new uncle to block", "hash", hash)
				uncles = append(uncles, uncle.Header())
			}
		}
		for _, hash := range badUncles {
			delete(self.possibleUncles, hash)
		}
		// Create the new block to seal with the consensus engine
		// ä½¿ç”¨ç»™å®šçš„çŠ¶æ€æ¥åˆ›å»ºæ–°çš„åŒºå—ï¼ŒFinalizeä¼šè¿›è¡ŒåŒºå—å¥–åŠ±ç­‰æ“ä½œ
		if work.Block, err = self.engine.Finalize(self.chain, header, work.state, work.txs, uncles, work.receipts); err != nil {
			log.Error("Failed to finalize block for sealing", "err", err)
			return
		}
		// We only care about logging if we're actually mining.
		// 
		if atomic.LoadInt32(&self.mining) == 1 {
			log.Info("Commit new mining work", "number", work.Block.Number(), "txs", work.tcount, "uncles", len(uncles), "elapsed", common.PrettyDuration(time.Since(tstart)))
			self.unconfirmed.Shift(work.Block.NumberU64() - 1)
		}
		self.push(work)
	}

pushæ–¹æ³•ï¼Œå¦‚æœæˆ‘ä»¬æ²¡æœ‰åœ¨æŒ–çŸ¿ï¼Œé‚£ä¹ˆç›´æ¥è¿”å›ï¼Œå¦åˆ™æŠŠä»»åŠ¡é€ç»™æ¯ä¸€ä¸ªagent
	
	// push sends a new work task to currently live miner agents.
	func (self *worker) push(work *Work) {
		if atomic.LoadInt32(&self.mining) != 1 {
			return
		}
		for agent := range self.agents {
			atomic.AddInt32(&self.atWork, 1)
			if ch := agent.Work(); ch != nil {
				ch <- work
			}
		}
	}

makeCurrentï¼Œæœªå½“å‰çš„å‘¨æœŸåˆ›å»ºä¸€ä¸ªæ–°çš„ç¯å¢ƒã€‚
	
	// makeCurrent creates a new environment for the current cycle.
	// 
	func (self *worker) makeCurrent(parent *types.Block, header *types.Header) error {
		state, err := self.chain.StateAt(parent.Root())
		if err != nil {
			return err
		}
		work := &Work{
			config:    self.config,
			signer:    types.NewEIP155Signer(self.config.ChainId),
			state:     state,
			ancestors: set.New(),
			family:    set.New(),
			uncles:    set.New(),
			header:    header,
			createdAt: time.Now(),
		}
	
		// when 08 is processed ancestors contain 07 (quick block)
		for _, ancestor := range self.chain.GetBlocksFromHash(parent.Hash(), 7) {
			for _, uncle := range ancestor.Uncles() {
				work.family.Add(uncle.Hash())
			}
			work.family.Add(ancestor.Hash())
			work.ancestors.Add(ancestor.Hash())
		}
	
		// Keep track of transactions which return errors so they can be removed
		work.tcount = 0
		self.current = work
		return nil
	}

commitTransactions
	
	func (env *Work) commitTransactions(mux *event.TypeMux, txs *types.TransactionsByPriceAndNonce, bc *core.BlockChain, coinbase common.Address) {
		// ç”±äºæ˜¯æ‰“åŒ…æ–°çš„åŒºå—ä¸­äº¤æ˜“ï¼Œæ‰€ä»¥å°†æ€» gasPool åˆå§‹åŒ–ä¸º env.header.GasLimit
		if env.gasPool == nil {
			env.gasPool = new(core.GasPool).AddGas(env.header.GasLimit)
		}
	
		var coalescedLogs []*types.Log
	
		for {
			// If we don't have enough gas for any further transactions then we're done
			// å¦‚æœå½“å‰åŒºå—ä¸­æ‰€æœ‰ Gas æ¶ˆè€—å·²ç»ä½¿ç”¨å®Œï¼Œåˆ™é€€å‡ºæ‰“åŒ…äº¤æ˜“
			if env.gasPool.Gas() < params.TxGas {
				log.Trace("Not enough gas for further transactions", "have", env.gasPool, "want", params.TxGas)
				break
			}
					
			// Retrieve the next transaction and abort if all done
			// æ£€ç´¢ä¸‹ä¸€ç¬”äº¤æ˜“ï¼Œå¦‚æœäº¤æ˜“é›†åˆä¸ºç©ºåˆ™é€€å‡º commit
			tx := txs.Peek()
			if tx == nil {
				break
			}
			// Error may be ignored here. The error has already been checked
			// during transaction acceptance is the transaction pool.
			//
			// We use the eip155 signer regardless of the current hf.
			from, _ := types.Sender(env.signer, tx)
			// Check whether the tx is replay protected. If we're not in the EIP155 hf
			// phase, start ignoring the sender until we do.
			// è¯·å‚è€ƒ https://github.com/ethereum/EIPs/blob/master/EIPS/eip-155.md
			// DAOäº‹ä»¶å‘ç”Ÿåï¼Œä»¥å¤ªåŠåˆ†è£‚ä¸ºETHå’ŒETC,å› ä¸ºä¸¤ä¸ªé“¾ä¸Šçš„ä¸œè¥¿ä¸€æ‘¸ä¸€æ ·ï¼Œæ‰€ä»¥åœ¨ETC
			// ä¸Šé¢å‘ç”Ÿçš„äº¤æ˜“å¯ä»¥æ‹¿åˆ°ETHä¸Šé¢è¿›è¡Œé‡æ”¾ï¼Œ åä¹‹äº¦ç„¶ã€‚ æ‰€ä»¥Vitalikæå‡ºäº†EIP155æ¥é¿å…è¿™ç§æƒ…å†µã€‚
			if tx.Protected() && !env.config.IsEIP155(env.header.Number) {
				log.Trace("Ignoring reply protected transaction", "hash", tx.Hash(), "eip155", env.config.EIP155Block)
	
				txs.Pop()
				continue
			}
			// Start executing the transaction
			env.state.Prepare(tx.Hash(), common.Hash{}, env.tcount)
			// æ‰§è¡Œäº¤æ˜“
			err, logs := env.commitTransaction(tx, bc, coinbase, gp)
			switch err {
			case core.ErrGasLimitReached:
				// Pop the current out-of-gas transaction without shifting in the next from the account
				// å¼¹å‡ºæ•´ä¸ªè´¦æˆ·çš„æ‰€æœ‰äº¤æ˜“ï¼Œ ä¸å¤„ç†ç”¨æˆ·çš„ä¸‹ä¸€ä¸ªäº¤æ˜“ã€‚
				log.Trace("Gas limit exceeded for current block", "sender", from)
				txs.Pop()
	
			case core.ErrNonceTooLow:
				// New head notification data race between the transaction pool and miner, shift
				// ç§»åŠ¨åˆ°ç”¨æˆ·çš„ä¸‹ä¸€ä¸ªäº¤æ˜“
				log.Trace("Skipping transaction with low nonce", "sender", from, "nonce", tx.Nonce())
				txs.Shift()
	
			case core.ErrNonceTooHigh:
				// Reorg notification data race between the transaction pool and miner, skip account =
				// è·³è¿‡è¿™ä¸ªè´¦æˆ·
				log.Trace("Skipping account with hight nonce", "sender", from, "nonce", tx.Nonce())
				txs.Pop()
	
			case nil:
				// Everything ok, collect the logs and shift in the next transaction from the same account
				coalescedLogs = append(coalescedLogs, logs...)
				env.tcount++
				txs.Shift()
	
			default:
				// Strange error, discard the transaction and get the next in line (note, the
				// nonce-too-high clause will prevent us from executing in vain).
				// å…¶ä»–å¥‡æ€ªçš„é”™è¯¯ï¼Œè·³è¿‡è¿™ä¸ªäº¤æ˜“ã€‚
				log.Debug("Transaction failed, account skipped", "hash", tx.Hash(), "err", err)
				txs.Shift()
			}
		}
	
		if len(coalescedLogs) > 0 || env.tcount > 0 {
			// make a copy, the state caches the logs and these logs get "upgraded" from pending to mined
			// logs by filling in the block hash when the block was mined by the local miner. This can
			// cause a race condition if a log was "upgraded" before the PendingLogsEvent is processed.
			// å› ä¸ºéœ€è¦æŠŠlogå‘é€å‡ºå»ï¼Œè€Œè¿™è¾¹åœ¨æŒ–çŸ¿å®Œæˆåéœ€è¦å¯¹logè¿›è¡Œä¿®æ”¹ï¼Œæ‰€ä»¥æ‹·è´ä¸€ä»½å‘é€å‡ºå»ï¼Œé¿å…äº‰ç”¨ã€‚
			cpy := make([]*types.Log, len(coalescedLogs))
			for i, l := range coalescedLogs {
				cpy[i] = new(types.Log)
				*cpy[i] = *l
			}
			go func(logs []*types.Log, tcount int) {
				if len(logs) > 0 {
					mux.Post(core.PendingLogsEvent{Logs: logs})
				}
				if tcount > 0 {
					mux.Post(core.PendingStateEvent{})
				}
			}(cpy, env.tcount)
		}
	}

commitTransactionæ‰§è¡ŒApplyTransaction
	
	func (env *Work) commitTransaction(tx *types.Transaction, bc *core.BlockChain, coinbase common.Address, gp *core.GasPool) (error, []*types.Log) {
		snap := env.state.Snapshot()
	
		receipt, _, err := core.ApplyTransaction(env.config, bc, &coinbase, gp, env.state, env.header, tx, env.header.GasUsed, vm.Config{})
		if err != nil {
			env.state.RevertToSnapshot(snap)
			return err, nil
		}
		env.txs = append(env.txs, tx)
		env.receipts = append(env.receipts, receipt)
	
		return nil, receipt.Logs
	}

waitå‡½æ•°ç”¨æ¥æ¥å—æŒ–çŸ¿çš„ç»“æœç„¶åå†™å…¥æœ¬åœ°åŒºå—é“¾ï¼ŒåŒæ—¶é€šè¿‡ethåè®®å¹¿æ’­å‡ºå»ã€‚
	
	func (self *worker) wait() {
		for {
			mustCommitNewWork := true
			for result := range self.recv {
				atomic.AddInt32(&self.atWork, -1)
	
				if result == nil {
					continue
				}
				block := result.Block
				work := result.Work
	
				// Update the block hash in all logs since it is now available and not when the
				// receipt/log of individual transactions were created.
				for _, r := range work.receipts {
					for _, l := range r.Logs {
						l.BlockHash = block.Hash()
					}
				}
				for _, log := range work.state.Logs() {
					log.BlockHash = block.Hash()
				}
				stat, err := self.chain.WriteBlockAndState(block, work.receipts, work.state)
				if err != nil {
					log.Error("Failed writing block to chain", "err", err)
					continue
				}
				// check if canon block and write transactions
				if stat == core.CanonStatTy { // è¯´æ˜å·²ç»æ’å…¥åˆ°è§„èŒƒçš„åŒºå—é“¾
					// implicit by posting ChainHeadEvent
					// å› ä¸ºè¿™ç§çŠ¶æ€ä¸‹ï¼Œä¼šå‘é€ChainHeadEventï¼Œä¼šè§¦å‘ä¸Šé¢çš„updateé‡Œé¢çš„ä»£ç ï¼Œè¿™éƒ¨åˆ†ä»£ç ä¼šcommitNewWorkï¼Œæ‰€ä»¥åœ¨è¿™é‡Œå°±ä¸éœ€è¦commitäº†ã€‚
					mustCommitNewWork = false
				}	
				// Broadcast the block and announce chain insertion event
				// å¹¿æ’­åŒºå—ï¼Œå¹¶ä¸”ç”³æ˜åŒºå—é“¾æ’å…¥äº‹ä»¶ã€‚
				self.mux.Post(core.NewMinedBlockEvent{Block: block})
				var (
					events []interface{}
					logs   = work.state.Logs()
				)
				events = append(events, core.ChainEvent{Block: block, Hash: block.Hash(), Logs: logs})
				if stat == core.CanonStatTy {
					events = append(events, core.ChainHeadEvent{Block: block})
				}
				self.chain.PostChainEvents(events, logs)
	
				// Insert the block into the set of pending ones to wait for confirmations
				// æ’å…¥æœ¬åœ°è·Ÿè¸ªåˆ—è¡¨ï¼Œ æŸ¥çœ‹åç»­çš„ç¡®è®¤çŠ¶æ€ã€‚
				self.unconfirmed.Insert(block.NumberU64(), block.Hash())
	
				if mustCommitNewWork { // TODO ? 
					self.commitNewWork()
				}
			}
		}
	}


## miner
minerç”¨æ¥å¯¹workerè¿›è¡Œç®¡ç†ï¼Œ è®¢é˜…å¤–éƒ¨äº‹ä»¶ï¼Œæ§åˆ¶workerçš„å¯åŠ¨å’Œåœæ­¢ã€‚

æ•°æ®ç»“æ„

	
	// Backend wraps all methods required for mining.
	type Backend interface {
		AccountManager() *accounts.Manager
		BlockChain() *core.BlockChain
		TxPool() *core.TxPool
		ChainDb() ethdb.Database
	}
	
	// Miner creates blocks and searches for proof-of-work values.
	type Miner struct {
		mux *event.TypeMux
	
		worker *worker
	
		coinbase common.Address
		mining   int32
		eth      Backend
		engine   consensus.Engine
	
		canStart    int32 // can start indicates whether we can start the mining operation
		shouldStart int32 // should start indicates whether we should start after sync
	}


æ„é€ , åˆ›å»ºäº†ä¸€ä¸ªCPU agent å¯åŠ¨äº†minerçš„update goroutine

	
	func New(eth Backend, config *params.ChainConfig, mux *event.TypeMux, engine consensus.Engine) *Miner {
		miner := &Miner{
			eth:      eth,
			mux:      mux,
			engine:   engine,
			worker:   newWorker(config, engine, common.Address{}, eth, mux),
			canStart: 1,
		}
		miner.Register(NewCpuAgent(eth.BlockChain(), engine))
		go miner.update()
	
		return miner
	}

updateè®¢é˜…äº†downloaderçš„äº‹ä»¶ï¼Œ æ³¨æ„è¿™ä¸ªgoroutineæ˜¯ä¸€ä¸ªä¸€æ¬¡æ€§çš„å¾ªç¯ï¼Œ åªè¦æ¥æ”¶åˆ°ä¸€æ¬¡downloaderçš„downloader.DoneEventæˆ–è€… downloader.FailedEventäº‹ä»¶ï¼Œ å°±ä¼šè®¾ç½®canStartä¸º1. å¹¶é€€å‡ºå¾ªç¯ï¼Œ è¿™æ˜¯ä¸ºäº†é¿å…é»‘å®¢æ¶æ„çš„ DOSæ”»å‡»ï¼Œè®©ä½ ä¸æ–­çš„å¤„äºå¼‚å¸¸çŠ¶æ€
	
	// update keeps track of the downloader events. Please be aware that this is a one shot type of update loop.
	// It's entered once and as soon as `Done` or `Failed` has been broadcasted the events are unregistered and
	// the loop is exited. This to prevent a major security vuln where external parties can DOS you with blocks
	// and halt your mining operation for as long as the DOS continues.
	func (self *Miner) update() {
		events := self.mux.Subscribe(downloader.StartEvent{}, downloader.DoneEvent{}, downloader.FailedEvent{})
	out:
		for ev := range events.Chan() {
			switch ev.Data.(type) {
			case downloader.StartEvent:
				atomic.StoreInt32(&self.canStart, 0)
				if self.Mining() {
					self.Stop()
					atomic.StoreInt32(&self.shouldStart, 1)
					log.Info("Mining aborted due to sync")
				}
			case downloader.DoneEvent, downloader.FailedEvent:
				shouldStart := atomic.LoadInt32(&self.shouldStart) == 1
	
				atomic.StoreInt32(&self.canStart, 1)
				atomic.StoreInt32(&self.shouldStart, 0)
				if shouldStart {
					self.Start(self.coinbase)
				}
				// unsubscribe. we're only interested in this event once
				events.Unsubscribe()
				// stop immediately and ignore all further pending events
				break out
			}
		}
	}

Start
	
	func (self *Miner) Start(coinbase common.Address) {
		atomic.StoreInt32(&self.shouldStart, 1)  // shouldStart æ˜¯æ˜¯å¦åº”è¯¥å¯åŠ¨
		self.worker.setEtherbase(coinbase)	     
		self.coinbase = coinbase
	
		if atomic.LoadInt32(&self.canStart) == 0 {  // canStartæ˜¯å¦èƒ½å¤Ÿå¯åŠ¨ï¼Œ
			log.Info("Network syncing, will start miner afterwards")
			return
		}
		atomic.StoreInt32(&self.mining, 1)
	
		log.Info("Starting mining operation")
		self.worker.start()  // å¯åŠ¨worker å¼€å§‹æŒ–çŸ¿
		self.worker.commitNewWork()  //æäº¤æ–°çš„æŒ–çŸ¿ä»»åŠ¡ã€‚
	}
